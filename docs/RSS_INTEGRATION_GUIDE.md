# ğŸ“¡ RSS Integration Guide (Phase 2 Expansion)

**ç›®æ¨™**ï¼šå°‡ Kazuha Invest 2.0 å¾ã€Œä¸»å‹•ç‹©çµ (Keyword Search)ã€å‡ç´šè‡³ã€Œè¢«å‹•æ„ŸçŸ¥ (RSS Feeds)ã€ï¼Œæ•æ‰æœªçŸ¥äºŒéšæ©Ÿæœƒã€‚

---

## ğŸ§  æ ¸å¿ƒç­–ç•¥ï¼šé›·é”ç«™æ¶æ§‹ (Radar Architecture)

### ç•¶å‰ç³»çµ± (Phase 1)
```
[DuckDuckGo Search] â†’ [Incoming/*.json] â†’ [Brain Analysis]
   â†‘ ä¸»å‹•ï¼šåªæ‰¾ä½ çŸ¥é“çš„é—œéµå­—
```

### å‡ç´šå¾Œç³»çµ± (Phase 2)
```
[RSS Feeds]     â”€â”€â”
[DDG Hunter]    â”€â”€â”¼â”€â†’ [Rule Filter] â†’ [Semantic Dedup] â†’ data/Incoming/consolidated_YYYYMMDD.json
[DDG Shield]    â”€â”€â”˜                                              â†“
                                                        [Brain Reasoning] â†’ Reports/
```
**æ•¸æ“šæµå‘èªªæ˜**ï¼š
1. **åŸå§‹æ•¸æ“š** (`data/Incoming/`):
   - `rss_results_*.json` â€” RSS Feed æŠ“å–çµæœ
   - `hunter_results_*.json` â€” å®è§€ä¸»é¡Œæœå°‹çµæœ
   - `shield_results_*.json` â€” æŒå€‰é¢¨éšªç›£æ¸¬çµæœ

2. **åˆä½µå»é‡** (`src/scout_dedup.py`):
   - è®€å–ä¸Šè¿°æ‰€æœ‰ `*_results_*.json`
   - åŸ·è¡Œèªç¾©å»é‡ (Embedding Similarity)
   - è¼¸å‡º â†’ `data/Incoming/consolidated_YYYYMMDD.json` â­

3. **æœ¬åœ°æ¨ç†** (`src/brain_reasoning.py`):
   - **åªè®€å–** `consolidated_*.json`ï¼ˆå·²å»é‡çš„é«˜è³ªé‡æ•¸æ“šï¼‰
   - ç”Ÿæˆ Daily Alpha å ±å‘Š

---

## ğŸ“‹ å¯¦æ–½æ­¥é©Ÿ (Implementation Plan)

### Step 1: å»ºç«‹ RSS ä¾†æºæ¸…å–®

å»ºç«‹æª”æ¡ˆï¼š`data/sources.yml`

```yaml
# Tier 1: ä½å™ªéŸ³ï¼Œé«˜ç›¸é—œï¼ˆç¬¬ä¸€é€±å…ˆåŠ å‘¢å•²ï¼‰
tier1:
  - name: SpaceNews
    url: https://spacenews.com/feed/
    category: Space Tech
    portfolio_relevance: [RKLB]
    priority: high

  - name: World Nuclear News
    url: https://world-nuclear-news.org/RSS
    category: Advanced Nuclear
    portfolio_relevance: []
    priority: high
    
  - name: Electrek
    url: https://electrek.co/feed/
    category: Automotive/EV
    portfolio_relevance: [TSLA]
    priority: high
    
  - name: Ars Technica Science
    url: https://feeds.arstechnica.com/arstechnica/science
    category: Advanced Nuclear, Space
    portfolio_relevance: []
    priority: medium

# Tier 2: ä¸­å™ªéŸ³ï¼ˆç¬¬äºŒé€±æ¸¬è©¦ï¼‰
tier2:
  - name: SemiEngineering
    url: https://semiengineering.com/feed/
    category: Semiconductors, Photonics
    portfolio_relevance: [POET]
    priority: medium
    
  - name: Hacker News (Filtered)
    url: https://hnrss.org/newest?points=100
    category: Tech Breakthrough
    portfolio_relevance: []
    priority: low
```

---

### Step 2: é–‹ç™¼ RSS Scout (`src/scout_feed.py`)

#### æ¶æ§‹é‚è¼¯
```python
# Pseudo-code
def scout_feed():
    # 1. Load RSS sources from data/sources.yml
    sources = load_yaml("data/sources.yml")
    
    # 2. Fetch RSS feeds
    all_entries = []
    for source in sources['tier1']:  # å…ˆåªè·‘ tier1
        entries = feedparser.parse(source['url']).entries
        all_entries.extend(entries)
    
    # 3. Rule-based Pre-filter (ç¬¬ä¸€å±¤éæ¿¾)
    filtered = [e for e in all_entries if quick_filter(e)]
    
    # 3.1 Health Check (å¥åº·æª¢æŸ¥)
    # Log if a source returns 0 entries for multiple days
    
    # 4. AI Semantic Filter (ç¬¬äºŒå±¤éæ¿¾) - Optional
    # final = ai_relevance_filter(filtered)
    
    # 5. Save to Incoming/
    save_json(filtered, "data/Incoming/rss_results_{timestamp}.json")
```

#### ç¬¬ä¸€å±¤ï¼šRule-based Filter (å…è²»ï¼Œå¿«é€Ÿ)

```python
def quick_filter(entry):
    """
    å¿«é€Ÿéæ¿¾è¦å‰‡ï¼Œæ¸›å°‘ AI è™•ç†é‡
    """
    title = entry.get('title', '').lower()
    summary = entry.get('summary', '').lower() # æƒææ‘˜è¦ä»¥é˜²æ¨™é¡Œé»¨
    url = entry.get('link', '')
    content = title + " " + summary
    
    # æ’é™¤é—œéµå­— (Negative Keywords) - æ¸›å°‘å™ªéŸ³
    NEGATIVE_KEYWORDS = ['tutorial', 'how to', 'review', 'podcast', 'video only', 'giveaway']
    if any(nw in content for nw in NEGATIVE_KEYWORDS):
        return False

    # ç™½åå–®ï¼šå¯ä¿¡ä¾†æºç›´æ¥é€šé
    TRUSTED_DOMAINS = ['spacenews.com', 'eetimes.com', 'semiengineering.com', 'world-nuclear-news.org']
    if any(domain in url for domain in TRUSTED_DOMAINS):
        return True
    
    # æŒå€‰é—œéµå­—ï¼šå¦‚æœæåˆ°ä½ çš„è‚¡ç¥¨
    PORTFOLIO_KEYWORDS = ['rklb', 'rocket lab', 'tesla', 'tsla', 
                          'poet', 'photonics', 'ondas']
    if any(kw in content for kw in PORTFOLIO_KEYWORDS):
        return True
    
    # è²¡ç¶“ä¿¡è™Ÿï¼šIPOã€ä½µè³¼ã€æ–°ç”¢å“
    FINANCIAL_SIGNALS = ['ipo', 'acquired', 'acquisition', 'partnership', 
                         'raises $', 'closes $', 'announces']
    if any(signal in content for signal in FINANCIAL_SIGNALS):
        return True
    
    # æŠ€è¡“çªç ´ä¿¡è™Ÿ
    TECH_SIGNALS = ['breakthrough', 'first ever', 'record', 'milestone']
    if any(signal in content for signal in TECH_SIGNALS):
        return True
    
    # å…¶ä»–å…¨éƒ¨éæ¿¾æ‰
    return False
```

**é æœŸæ•ˆæœ**ï¼š500æ¢ RSS â†’ éæ¿¾å¾Œå‰© **50-80 æ¢**ã€‚

---

### Step 3: èªç¾©å»é‡ (Semantic Deduplication)

#### ç‚ºä»€éº¼éœ€è¦ï¼Ÿ
- DuckDuckGo æµåˆ°ï¼š*"Rocket Lab Launches Satellite for NASA"* (Source: Reuters)
- RSS æŠ“åˆ°ï¼š*"RKLB Mission Success for NASA Contract"* (Source: SpaceNews)
- **å•é¡Œ**ï¼šå…©ç¯‡è¬›åŒä¸€ä»¶äº‹ï¼Œä½†æ¨™é¡Œå””åŒã€‚

#### è§£æ±ºæ–¹æ¡ˆï¼šVector Embedding + Cosine Similarity
- **è·¨æ™‚é–“è¦–çª— (Time Window)**ï¼šå»ºç«‹ `history_hashes.json` è¨˜éŒ„éå» 48 å°æ™‚å·²è™•ç†çš„æ¨™é¡Œï¼Œé˜²æ­¢è·¨æ™‚æ®µé‡è¤‡å ±å‘Šã€‚

```python
from sentence_transformers import SentenceTransformer
import numpy as np

def semantic_dedup(articles):
    """
    ä½¿ç”¨ Gemini Embedding API æˆ– SentenceTransformer æœ¬åœ°æ¨¡å‹
    """
    # 1. å°‡æ¯ç¯‡æ–‡ç« çš„æ¨™é¡Œ+æ‘˜è¦è½‰æˆ Vector
    model = SentenceTransformer('all-MiniLM-L6-v2')  # æœ¬åœ°å…è²»æ¨¡å‹
    embeddings = [model.encode(a['title'] + ' ' + a.get('summary', '')) 
                  for a in articles]
    
    # 2. è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
    similarity_matrix = cosine_similarity(embeddings)
    
    # 3. å»é‡é‚è¼¯
    to_remove = set()
    for i in range(len(articles)):
        for j in range(i+1, len(articles)):
            if similarity_matrix[i][j] > 0.85:  # ç›¸ä¼¼åº¦é–¾å€¼
                # ä¿ç•™ä¾†æºæ¬Šå¨æ€§é«˜çš„
                if is_more_authoritative(articles[i], articles[j]):
                    to_remove.add(j)
                else:
                    to_remove.add(i)
    
    # 4. ç§»é™¤é‡è¤‡é …
    return [a for idx, a in enumerate(articles) if idx not in to_remove]

def is_more_authoritative(article1, article2):
    """
    å®šç¾©ä¾†æºæ¬Šå¨æ€§æ’åº
    """
    AUTHORITY_RANK = {
        'reuters.com': 10,
        'bloomberg.com': 10,
        'spacenews.com': 9,
        'eetimes.com': 9,
        'techcrunch.com': 7,
        'default': 5
    }
    score1 = max([AUTHORITY_RANK.get(d, 5) for d in AUTHORITY_RANK if d in article1['url']])
    score2 = max([AUTHORITY_RANK.get(d, 5) for d in AUTHORITY_RANK if d in article2['url']])
    return score1 > score2
```

---

### Step 4: æ›´æ–° GitHub Actions Workflow

ä¿®æ”¹ `.github/workflows/daily_brief.yml`ï¼ŒåŠ å…¥ RSS Scoutï¼š

```yaml
- name: Run RSS Scout (Passive Sensing)
  run: uv run python src/scout_feed.py
  env:
    PYTHONUNBUFFERED: 1

- name: Run Shield Scout (Defense)
  run: uv run python src/scout_shield.py

- name: Run Hunter Scout (Offense)
  run: uv run python src/scout_hunter.py
```

**åŸ·è¡Œé †åº**ï¼šRSS Feed â†’ Shield â†’ Hunter â†’ Dedup â†’ Push Data

---

## ğŸ¯ åˆ†éšæ®µæ¸¬è©¦è¨ˆåŠƒ

### Week 1: Tier 1 Only (ä½é¢¨éšª)
- åªé–‹ **SpaceNews + Electrek + Ars Technica**
- é©—è­‰ï¼šRule Filter èƒ½å¦å°‡å™ªéŸ³æ§åˆ¶åœ¨ 50 æ¢ä»¥å…§ï¼Ÿ
- é©—è­‰ï¼šèªç¾©å»é‡æ˜¯å¦æœ‰æ•ˆï¼Ÿ

### Week 2: åŠ å…¥ä¸­å™ªéŸ³æº
- åŠ  **SemiEngineering**ï¼ˆé‡å° POETï¼‰
- è§€å¯Ÿï¼šAI Filter æ˜¯å¦éœ€è¦ä»‹å…¥ï¼Ÿ

### Week 3: é«˜å™ªéŸ³æŒ‘æˆ°
- åŠ  **Hacker News (Filtered)**
- æ¸¬è©¦ï¼šç™½åå–® domain ç­–ç•¥æ˜¯å¦æœ‰æ•ˆï¼Ÿ

### Week 4: å…¨é¢è©•ä¼°
- å°æ¯”æœ‰ç„¡ RSS çš„ Alpha ç™¼ç¾ç‡
- æ±ºå®šæ˜¯å¦æ°¸ä¹…ä¿ç•™

---

## ğŸ”§ æŠ€è¡“ä¾è³´ (Dependencies)

### Python å¥—ä»¶
```bash
uv pip install feedparser sentence-transformers scikit-learn
```

### å¯é¸ï¼šä½¿ç”¨ Gemini Embedding API (å…è²»é¡åº¦å¤§)
```python
import google.generativeai as genai

def get_embedding(text):
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text
    )
    return result['embedding']
```

---

## ğŸ“Š é æœŸæˆæœ¬èˆ‡æ•ˆç›Š

### æˆæœ¬
- **è¨ˆç®—æˆæœ¬**ï¼šRule Filter (å…è²») + Local Embedding Model (å…è²»)
- **API æˆæœ¬**ï¼šå¦‚æœç”¨ Gemini Embedding APIï¼Œæ¯æ—¥ 500 æ¬¡èª¿ç”¨ â‰ˆ $0 (åœ¨å…è²»é¡åº¦å…§)

### æ•ˆç›Š
- **ç™¼ç¾ç‡æå‡**ï¼šé è¨ˆèƒ½æ•æ‰åˆ° **15-20% çš„ã€ŒæœªçŸ¥æ©Ÿæœƒã€**ï¼ˆå³ä½ åŸæœ¬ä¸çŸ¥é“è¦æœçš„é—œéµå­—ï¼‰
- **æ™‚é–“å¥—åˆ©**ï¼šRSS é€šå¸¸æ¯” Google News å¿« 2-6 å°æ™‚ï¼ˆå› ç‚º RSS æ˜¯ç›´æ¥æ¨é€ï¼‰

---

## âš ï¸ é¢¨éšªèˆ‡ç·©è§£

| é¢¨éšª | å½±éŸ¿ | ç·©è§£æªæ–½ |
|------|------|---------|
| **å™ªéŸ³çˆ†ç‚¸** | å ±å‘Šå¤ªé•·ï¼Œé›£ä»¥é–±è®€ | åš´æ ¼åŸ·è¡Œ Rule Filterï¼ŒåˆæœŸåªé–‹ Tier 1 |
| **é‡è¤‡éå¤š** | æµªè²» AI åˆ†ææ™‚é–“ | å¯¦æ–½èªç¾©å»é‡ï¼ˆå¿…é ˆï¼‰ |
| **èª¤å ±éæ¿¾** | æ¼æ‰é‡è¦æ–°è | å®šæœŸ Review è¢«éæ¿¾æ‰çš„å…§å®¹ (Logging) |
| **RSS æºå¤±æ•ˆ** | æ•¸æ“šæ–·æµ | å®šæœŸæª¢æŸ¥ RSS æ˜¯å¦ä»ç„¶æœ‰æ•ˆ |

---

## ğŸ“ çµ¦æœªä¾† Agent çš„æŒ‡ä»¤

> "Agentï¼Œè«‹å¯¦æ–½ RSS Integration Phase 2ã€‚é¦–å…ˆå»ºç«‹ `data/sources.yml` ä¸¦åªåŠ å…¥ Tier 1 ä¾†æºï¼Œç„¶å¾Œé–‹ç™¼ `src/scout_feed.py` å¯¦ä½œ Rule Filter èˆ‡èªç¾©å»é‡ã€‚æ¸¬è©¦ä¸€é€±å¾Œå†æ±ºå®šæ˜¯å¦æ“´å±•è‡³ Tier 2ã€‚è¨˜ä½ï¼šå¯§å¯æ¼éä¸€æ¢æ–°èï¼Œä¹Ÿä¸è¦è¢«å™ªéŸ³æ·¹æ²’ã€‚"

---

## ğŸ”— åƒè€ƒè³‡æº

- **RSS Best Practices**: https://www.rssboard.org/rss-specification
- **Sentence Transformers**: https://www.sbert.net/
- **Gemini Embedding API**: https://ai.google.dev/gemini-api/docs/embeddings
